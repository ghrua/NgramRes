{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Dictionary\n",
    "tokenizer = Dictionary.load(\"../data-bin/iwslt15.en-vi//dict.vi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s>', 't√¥i', '.']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer[wi] for wi in [2, 7, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "</s>\n",
      "=\n",
      "Robert\n",
      "Boul@@\n",
      "ter\n",
      "=\n",
      "</s>\n",
      "</s>\n",
      "Robert\n"
     ]
    }
   ],
   "source": [
    "for wi in [    2,     2,    12,   764, 12142,  1110,    12,     2,     2,   764]:\n",
    "    print(tokenizer[wi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 119723512 contexts from 120 cache files\n"
     ]
    }
   ],
   "source": [
    "import c_fast_model\n",
    "sos_id, unk_id = tokenizer.index(\"</s>\"), tokenizer.index(\"<unk>\")\n",
    "lm = c_fast_model.CMultiFastGenerationModel.from_cache(\"cache_5gram_wt103_bpe/wiki.train.tokens.bpe.repunk.arpa.cache\", sos_id, unk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[tokenizer.index(it) for it in \"= Robert Boulter =\".strip().split()]]\n",
    "word3d_p09, prob3d_p09, ctxlen3d_p09 = lm.batch_dist(data, dist_size=10000, min_dist_prob=0.95, bos=False, require_match_len=True, ctxlens=None)\n",
    "# word3d_p10, prob3d_p10, ctxlen3d_p10 = lm.batch_dist(data, dist_size=10000, min_dist_prob=1.0, bos=False, require_match_len=True, ctxlens=None)\n",
    "# word3d_def, prob3d_def, ctxlen3d_def = lm.batch_dist(data, dist_size=10000, bos=False, require_match_len=True, ctxlens=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9858853844938352\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(sum(10 ** p for p in prob3d_p10[0][2] if p < 0))\n",
    "print(len(prob3d_p09[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 2, 1, 2, 2, 1, 1, 2]\n",
      "7 10 10\n",
      "1\n",
      "0 True\n",
      "1\n",
      "1 True\n",
      "2\n",
      "2 True\n",
      "2\n",
      "3 False\n",
      "1\n",
      "4 True\n",
      "2\n",
      "5 True\n",
      "2\n",
      "6 True\n",
      "1\n",
      "7 True\n",
      "1\n",
      "8 True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "str_data = [\"</s>\", \"</s>\", \"=\", \"Robert\", \"Boul@@\", \"ter\", \"=\"]\n",
    "# data = [tokenizer.index(\"</s>\"), tokenizer.index(\"</s>\"), tokenizer.index(\"=\"), tokenizer.index(\"Boul@@\"),  tokenizer.index(\"ter\"), tokenizer.index(\"=\")]\n",
    "data = [    2,     2,    12,   764, 12142,  1110,    12,     2,     2,   764]\n",
    "word2d, prob2d, ctxlen2d  = lm.sent_dist(data, dist_size=100, bos=False, require_match_len=True)\n",
    "print([it[0] for it in ctxlen2d])\n",
    "print(len(str_data), len(data), len(word2d))\n",
    "for sm, words in enumerate(word2d):\n",
    "    print(ctxlen2d[sm][0])\n",
    "    if sm == len(word2d) - 1:\n",
    "        break\n",
    "    flag = data[sm+1] in word2d[sm]\n",
    "    print(sm, flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEST=\"/mnt/task_wrapper/user_output/artifacts/\"\n",
    "train_data = torch.load(DEST+\"/results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16//checkpoint_best.pt.train.pd.pt\")\n",
    "valid_data = torch.load(DEST+\"/results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16//checkpoint_best.pt.valid.pd.pt\")\n",
    "\n",
    "valid_data = sorted(valid_data, key=lambda x: x[0])\n",
    "\n",
    "def func(data):\n",
    "    src = [[tokenizer.index(w) for w in it[2]] for it in data]\n",
    "    tgt = []\n",
    "    for it in data:\n",
    "        for w in it[3]:\n",
    "            tgt.append(tokenizer.index(w))\n",
    "    tgt = torch.tensor(tgt, dtype=torch.int)\n",
    "    tgt = tgt.unsqueeze(-1).repeat(1, 100)\n",
    "    word3d, prob3d, ctxlen3d = lm.batch_dist(\n",
    "                src, dist_size=100, bos=False, require_match_len=True, ctxlens=None)\n",
    "    ngram_ctxlen = []\n",
    "    for sent in ctxlen3d:\n",
    "        for it in sent:\n",
    "            ngram_ctxlen.append(it[0])\n",
    "    ngram_ctxlen = torch.tensor(ngram_ctxlen, dtype=torch.int)\n",
    "    ngram_word = []\n",
    "    for it in word3d:\n",
    "        for dist in it:\n",
    "            ngram_word.append(dist)\n",
    "    ngram_word = torch.tensor(ngram_word, dtype=torch.long)\n",
    "    gd_match = tgt.eq(ngram_word).sum(dim=-1)\n",
    "    return ngram_ctxlen.tolist(), gd_match.tolist()\n",
    "\n",
    "train_info = func(train_data)\n",
    "valid_info = func(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.609904202664413 13352\n"
     ]
    }
   ],
   "source": [
    "dist_list = []\n",
    "s = 0\n",
    "for it in valid_data:\n",
    "    e = s + len(it[-1])\n",
    "    pd_score = it[1]\n",
    "    orig_prob = it[1]\n",
    "    for i, (j, m, gd) in enumerate(zip(it[-1], valid_info[0][s:e], valid_info[1][s:e])):\n",
    "        if i < 3:\n",
    "            continue\n",
    "        values, indices = torch.topk(orig_prob[:i+1, i], k=min(i, 3))\n",
    "\n",
    "        indices = (indices.float() * values / values.sum()).sum()\n",
    "        if torch.isnan(indices):\n",
    "            continue\n",
    "        if m == 4:\n",
    "            dist_list.append(i-indices.item()+1)\n",
    "    s = e\n",
    "print(sum(dist_list) / len(dist_list), len(dist_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_ngram = torch.load(\"../fairseq-stable/prob.debug.pt\")\n",
    "print(len(data_ngram[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "ctxinfo = torch.load(\"./wiki.train.tokens.bpe.repunk.ctxinfo.went.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16/prob.xfm.valid.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/tmp/ipykernel_401096/2485198846.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m data = [\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_file_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/tmp/ipykernel_401096/2485198846.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m data = [\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_file_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py37_torch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py37_torch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py37_torch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16/prob.xfm.valid.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(404)\n",
    "\n",
    "data_file_list = [\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16/prob.xfm.valid.pt\",\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.1/prob.xfm.valid.0.1.pt\",\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.1/prob.xfm.valid.0.2.pt\",\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.4/prob.xfm.valid.0.4.pt\",\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.6/prob.xfm.valid.0.6.pt\"\n",
    "]\n",
    "\n",
    "\n",
    "data = [\n",
    "    torch.load(fname) for fname in data_file_list\n",
    "]\n",
    "\n",
    "\n",
    "# data = [\n",
    "#     sorted(torch.load(fname), key=lambda x: x[0]) for fname in data_file_list\n",
    "# ]\n",
    "\n",
    "aux_data = data[0]\n",
    "random.shuffle(aux_data)\n",
    "data_num = len(aux_data)\n",
    "\n",
    "# ctx_gd_info = dict()\n",
    "# ctx_alpha_info = dict()\n",
    "\n",
    "pos_idx = []\n",
    "sorted_data = sorted(aux_data, key=lambda x: x[0])\n",
    "pos = 0\n",
    "for i in range(data_num):\n",
    "    tmp_idx = []\n",
    "    for j in range(len(sorted_data[i][2])):\n",
    "        tmp_idx.append(pos)\n",
    "        pos += 1\n",
    "    pos_idx.append(tmp_idx)\n",
    "\n",
    "\n",
    "max_ctxlen = 3\n",
    "my_ctx2ppl = []\n",
    "n = 0\n",
    "pos=0\n",
    "for i in range(data_num):\n",
    "    gd = aux_data[i][2]\n",
    "    ctxlens = aux_data[i][3]\n",
    "    src = aux_data[i][4]\n",
    "    prob = aux_data[i][1]\n",
    "    \n",
    "    for j in range(len(gd)):\n",
    "        ctx_key = tuple(src[j-max_ctxlen+1:j+1])\n",
    "        ctx_key_len = len(ctx_key) - 1\n",
    "        if ctx_key in ctxinfo[ctx_key_len]:\n",
    "            info = ctxinfo[ctx_key_len][ctx_key]\n",
    "            if info[0] == 1:\n",
    "                n+=1\n",
    "            my_ctx2ppl.append((info[-1], prob[j][1], pos_idx[aux_data[i][0]][j]))\n",
    "        pos += 1\n",
    "\n",
    "        # if ctx_key in ctx_gd_info:\n",
    "        #     ctx_gd_info[ctx_key].append(gd[j])\n",
    "        # else:\n",
    "        #     ctx_gd_info[ctx_key] = [gd[j]]\n",
    "        # max_prob = -float(\"inf\")\n",
    "        # max_k = 0\n",
    "        # for k in range(2):\n",
    "        #     prob = data[k][i][1][j][1]\n",
    "        #     if max_prob < prob:\n",
    "        #         max_prob = prob\n",
    "        #         max_k = k\n",
    "        # ctx_alpha_info[ctx_key] = 0.2 * max_k\n",
    "\n",
    "ctx2ppl = sorted(my_ctx2ppl, key=lambda x: x[0])\n",
    "bucks = []\n",
    "ppl_res = []\n",
    "freq_res = []\n",
    "pos_res = []\n",
    "\n",
    "for freq, prob, pos in ctx2ppl:\n",
    "    if len(bucks) >= 10000:\n",
    "        mean_freq = np.mean([it[0] for it in bucks])\n",
    "        ppl = np.exp(-sum([it[1] for it in bucks]) / len(bucks))\n",
    "        mean_pos = np.mean([it[-1] for it in bucks])\n",
    "        freq_res.append(mean_freq)\n",
    "        ppl_res.append(ppl)\n",
    "        pos_res.append(mean_pos)\n",
    "        bucks = []\n",
    "    bucks.append((freq, prob, pos))\n",
    "\n",
    "# print(len(bucks))\n",
    "# if bucks:\n",
    "#     mean_freq = np.mean([it[0] for it in bucks])\n",
    "#     ppl = np.exp(-sum([it[1] for it in bucks]) / len(bucks))\n",
    "#     freq_res.append(mean_freq)\n",
    "#     ppl_res.append(ppl)\n",
    "#     bucks = []\n",
    "\n",
    "print(freq_res)\n",
    "print([\"{:.2f}\".format(it) for it in ppl_res])\n",
    "print(pos_res)\n",
    "print(len(ctx2ppl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/tmp/ipykernel_196643/3395400768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mctx_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mword2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxlen2d\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dist_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_match_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mword_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxlen_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxlen2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mgrouped_ctx_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_ctxinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxlen_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pick the best prob in different systems\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "random.seed(404)\n",
    "\n",
    "\n",
    "def group_ctxinfo(word, prob, ctxlen):\n",
    "    group_dict = {\n",
    "        0: [], 1: [], 2: [], 3: [], 4: []\n",
    "    }\n",
    "    for i, l in enumerate(ctxlen):\n",
    "        if prob[i] > 0:\n",
    "            break\n",
    "        group_dict[l].append(i)\n",
    "    ret_dict = dict()\n",
    "    for m in range(5):\n",
    "        num = len(group_dict[m])\n",
    "        if num > 0:\n",
    "            ctxprob = sum([10 ** prob[it] for it in group_dict[m]])\n",
    "        else:\n",
    "            ctxprob = 0\n",
    "        ret_dict[m] = [num, ctxprob]\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "data_file_list = [\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16/prob.xfm.test.ctxwin1536.pt\",\n",
    "    # \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.seed404/prob.xfm.valid.ctxwin1536.pt\",\n",
    "    # \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.seed123/prob.xfm.valid.ctxwin1536.pt\",\n",
    "    # \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.seed10086/prob.xfm.valid.ctxwin1536.pt\",\n",
    "    # \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.1/prob.xfm.test.0.1.ctxwin1536.pt\",\n",
    "    # \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.2/prob.xfm.valid.0.2.ctxwin1536.pt\",\n",
    "    \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.4/prob.xfm.test.0.4.ctxwin1536.pt\",\n",
    "    # \"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.6/prob.xfm.valid.0.6.ctxwin1536.pt\"\n",
    "]\n",
    "\n",
    "cnt = 0\n",
    "data = [\n",
    "    sorted(torch.load(fname), key=lambda x: x[0]) for fname in data_file_list\n",
    "]\n",
    "ex_num = len(data[0])\n",
    "sys_num = len(data)\n",
    "\n",
    "prob_res = []\n",
    "sys_res = []\n",
    "\n",
    "word_num = 0\n",
    "prev_src_tokens = None\n",
    "alpha_pred_data = [[] for _ in range(sys_num)]\n",
    "\n",
    "gd_pred_test = torch.load(\"gd_pred_test.dat\")\n",
    "\n",
    "gd_pred_data = []\n",
    "gd_in_data = []\n",
    "gd_out_data = []\n",
    "global_index = 0\n",
    "for i in range(ex_num):\n",
    "    gd = data[0][i][2]\n",
    "    prob_ngram = data[0][i][1]\n",
    "    ctxlen = data[0][i][3]\n",
    "    src_token_sid = 0\n",
    "    src_tokens = data[0][i][4]\n",
    "    if prev_src_tokens is not None:\n",
    "        src_token_sid = len(prev_src_tokens)\n",
    "        src_tokens = prev_src_tokens + data[0][i][4]\n",
    "    prev_src_tokens = data[0][i][4]\n",
    "\n",
    "    for j in range(len(gd)):\n",
    "        ctx = []\n",
    "        for m in range(4):\n",
    "            ctx.append(src_tokens[src_token_sid+j-m])\n",
    "        ctx = ctx[::-1]\n",
    "        ctx_key = tuple(ctx)\n",
    "        \n",
    "        word2d, prob2d, ctxlen2d  = lm.sent_dist(ctx, dist_size=100, min_dist_prob=1.0, bos=False, require_match_len=True)\n",
    "        word_match, prob_match, ctxlen_match = word2d[-1], prob2d[-1], ctxlen2d[-1]\n",
    "        grouped_ctx_feat = group_ctxinfo(word_match, prob_match, ctxlen_match)\n",
    "        assert ctxlen2d[-1][0] == ctxlen[j]\n",
    "        ctx_feat = [global_index]\n",
    "        # info = list(ctxinfo[len(ctx_key) - 1][ctx_key])\n",
    "        # ctx_feat = [global_index, len(ctx_key), info[0], info[1], info[2]]\n",
    "        for m in range(5):\n",
    "            if grouped_ctx_feat[m][0] > 0:\n",
    "                if m > 0:\n",
    "                    cur_ctx_key = ctx_key[4-m:]\n",
    "                    cur_ctx_key_len = len(cur_ctx_key)-1\n",
    "                    info = list(ctxinfo[cur_ctx_key_len][cur_ctx_key])\n",
    "                else:\n",
    "                    # info = [114536634, 33339, 10.710820128231383]\n",
    "                    info = [1, 1, 1]\n",
    "            else:\n",
    "                info = [0, 0, 0]\n",
    "            ctx_feat += grouped_ctx_feat[m] + info\n",
    "        # assert ctx_key in ctxinfo[ctx_key_len]\n",
    "        \n",
    "        max_prob = 0\n",
    "        max_index = 0\n",
    "        min_prob = 999\n",
    "        min_index = 0\n",
    "        if not data[0][i][1][j][0].endswith(\"@@\"):\n",
    "            word_num += 1\n",
    "        # if gd[j] == 1:\n",
    "        if gd_pred_test[global_index] == gd[j]:\n",
    "            cnt += 1\n",
    "        if gd_pred_test[global_index] == 1:\n",
    "            p = np.exp(data[1][i][1][j][1])\n",
    "            prob_res.append(p)\n",
    "            ctx_feat.append(1)\n",
    "            gd_in_data.append(ctx_feat)\n",
    "            # gd_in_data.append((global_index, len(ctx_key), info[0], info[1], info[2], 1))\n",
    "            # in_gd_ctxset.append(ctx)\n",
    "        else:\n",
    "            p = np.exp(data[0][i][1][j][1])\n",
    "            prob_res.append(p)\n",
    "            ctx_feat.append(0)\n",
    "            gd_out_data.append(ctx_feat)\n",
    "            # gd_out_data.append((global_index, len(ctx_key), info[0], info[1], info[2], 0))\n",
    "        \n",
    "            # out_gd_ctxset.append(ctx)\n",
    "        for k in range(sys_num):\n",
    "            p = np.exp(data[k][i][1][j][1])\n",
    "            if p > max_prob:\n",
    "                max_prob = p\n",
    "                max_index = k\n",
    "            if p < min_prob:\n",
    "                min_prob = p\n",
    "                min_index = k\n",
    "        ctx_feat.append(max_index)\n",
    "        alpha_pred_data[max_index].append(ctx_feat)\n",
    "        prob_res.append(max_prob)\n",
    "        sys_res.append(max_index)\n",
    "        global_index += 1\n",
    "        # if max_prob - min_prob < 0.1:\n",
    "        #     continue\n",
    "        # alpha_pred_data.append((global_index, len(ctx_key), info[0], info[1], info[2], max_index))\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "print(\"{:.2f}\".format(np.exp(-sum(np.log(prob_res)) / len(prob_res))), len(prob_res))\n",
    "print(\"{:.2f}\".format(np.exp(-sum(np.log(prob_res)) / word_num), len(prob_res)), word_num)\n",
    "print(cnt / len(prob_res))\n",
    "torch.save(alpha_pred_data, \"alpha_valid_pred_pro_data_alpha0.4.dat\")\n",
    "# torch.save([gd_in_data, gd_out_data], \"gd_valid_pred_pro_data_alpha0.4.dat\")\n",
    "# print(len(gd_in_data), len(gd_out_data))\n",
    "print(Counter(sys_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "(4, 1, -1.4426951595367387e-09)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(data[0][1][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 81) [',', 'only'] [0, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "['8.10', '7.79', '6.54', '3.32', '15.28', '13.14', '13.54', '15.28', '18.87', '18.91', '21.43', '25.21', '28.81', '30.80', '38.89', '60.76']\n",
    "['7.69', '7.42', '6.19', '3.18', '14.64', '12.72', '12.91', '14.56', '18.31', '18.76', '20.89', '24.02', '27.84', '30.17', '39.08', '60.40']\n",
    "\n",
    "with open(\"./ctx_gd_info_t0.5.txt\", 'w') as fout:\n",
    "    n = 1\n",
    "    for ctx, gd_list in ctx_gd_info.items():\n",
    "        if n == 103:\n",
    "            print(ctx, [tokenizer[wi] for wi in ctx], gd_list)\n",
    "        n  += 1\n",
    "        val = sum(gd_list) / len(gd_list)\n",
    "        ctx_key_len = len(ctx)-1\n",
    "        info = ctxinfo[ctx_key_len][ctx]\n",
    "        # fout.write(\"{}\\t{}\\t{:.1f}\\n\".format(info[0], info[1], 0 if val <= 0.5 else 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# data_ngram = torch.load(\"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.2/prob.5gram.test.0.2.pt\")\n",
    "# data_gpt = torch.load(\"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16/prob.xfm.test.0.2.pt\")\n",
    "\n",
    "# data_ngram = sorted(data_ngram, key=lambda x: x[0])\n",
    "# data_gpt = sorted(data_gpt, key=lambda x: x[0])\n",
    "\n",
    "# score_list = []\n",
    "# n = 0\n",
    "\n",
    "# print(data_ngram[0][1][:10])\n",
    "# print(data_ngram[0][2][:10])\n",
    "# print(data_ngram[0][3][:10])\n",
    "\n",
    "\n",
    "# in_gd_ctxset = []\n",
    "# out_gd_ctxset = []\n",
    "# for i in range(len(data_gpt)):\n",
    "#     assert data_ngram[i][0] == data_gpt[i][0]\n",
    "#     gd = data_ngram[i][2]\n",
    "#     ctxlens = data_ngram[i][3]\n",
    "#     gpt_gd = data_gpt[i][2]\n",
    "#     prob_gpt = data_gpt[i][1]\n",
    "#     prob_ngram = data_ngram[i][1]\n",
    "#     assert len(prob_gpt) == len(prob_ngram) and len(prob_ngram) == len(gd)\n",
    "#     for a, b in zip(gd, gpt_gd):\n",
    "#         if a != b:\n",
    "#             raise Exception\n",
    "#     for j in range(len(gd)):\n",
    "#         ctx = []\n",
    "#         for k in range(ctxlens[j]):\n",
    "#             ctx.append(prob_ngram[j-k][0])\n",
    "#         ctx = ctx[::-1]\n",
    "#         if not prob_ngram[j][0].endswith(\"@@\"):\n",
    "#             n+=1\n",
    "#         # score_list.append(prob_gpt[j][1])\n",
    "#         if gd[j] == 1:\n",
    "#             score_list.append(prob_ngram[j][1])\n",
    "#             in_gd_ctxset.append(ctx)\n",
    "#         else:\n",
    "#             score_list.append(prob_gpt[j][1])\n",
    "#             out_gd_ctxset.append(ctx)\n",
    " \n",
    "# print(np.exp(-sum(score_list) / len(score_list)), len(score_list))\n",
    "# print(np.exp(-sum(score_list) / n), len(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "freq:  1251567.1552357625\n",
      "#cands:  11355.402173913044\n",
      "1\n",
      "freq:  36386.894782874886\n",
      "#cands:  1447.7589758166791\n",
      "2\n",
      "freq:  3336.9350377031333\n",
      "#cands:  213.04534457034558\n",
      "3\n",
      "freq:  166.42082744928064\n",
      "#cands:  35.14234979935963\n",
      "199497\n",
      "19580\n"
     ]
    }
   ],
   "source": [
    "# ctxinfo = torch.load(\"./wiki.train.tokens.bpe.repunk.ctxinfo.pt\")\n",
    "# in_gd_ctxinfo = dict()\n",
    "# fuck = []\n",
    "# for ctx in in_gd_ctxset:\n",
    "#     if ctx[0] == \"</s>\":\n",
    "#         ctx[0] = \"<s>\"\n",
    "#     key = tuple([tokenizer.index(it) for it in ctx])\n",
    "#     clen = len(key)-1\n",
    "#     if key not in ctxinfo[clen]:\n",
    "#         fuck.append(ctx)\n",
    "#         continue\n",
    "#     if clen in in_gd_ctxinfo:\n",
    "#         in_gd_ctxinfo[clen].append(ctxinfo[clen][key])\n",
    "#     else:\n",
    "#         in_gd_ctxinfo[clen] = [ctxinfo[clen][key]]\n",
    "\n",
    "# for k, v in in_gd_ctxinfo.items():\n",
    "#     print(k)\n",
    "#     print(\"freq: \", sum([it[0] for it in v]) / len(v))\n",
    "#     print(\"#cands: \", sum([it[1] for it in v]) / len(v))\n",
    "\n",
    "# print(len(in_gd_ctxset))\n",
    "# print(len(fuck))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_out = torch.load(\"../results/xfm.base.drop0.3.warm4k.wt103.bpe.fp16.5gram.0.2/checkpoint_best.pt.valid.pd.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ky@@', 'la', '.', 'I', \"'m\", 'very', 'sorry', 'to', 'have', 'to', 'let', 'her', 'go', '.', '\"', '</s>', '</s>', '=', '=', '=', 'Race', 'and', 'charity', 'work', '=', '=', '=', '</s>', '</s>', 'Throughout', 'her', 'career', ',', 'Ay@@', 'ola', 'has', 'been', 'outspoken', 'on', 'the', 'subject', 'of', 'racial', 'discrimination', 'in', 'the', 'entertainment', 'industry', '.', 'Describing', 'her', 'motivation', ',', 'she', 'states', ':', '\"', 'I', 'am', 'not', 'an', 'over@@', 'tly', 'political', 'person', '.', 'I', 'just', 'want', 'fair@@', 'ness', '\"', '.', 'Ay@@', 'ola', 'believes', 'that', 'black', 'actors', 'receive', 'less', 'recognition', 'than', 'their', 'white', 'counterparts', ',', 'explaining', ';', '\"', 'If', 'you', 'get', 'a', 'show', 'with', 'six', 'stars', 'and', 'one', 'is', 'black', 'you', 'are', 'more', 'likely', 'to', 'see', 'interviews', 'with', 'the', 'five', 'white', 'actors', '.', '[', '...', ']', 'They', 'are', 'not', 'being', 'sold', 'as', 'a', 'reason', 'to', 'watch', '.', '\"', 'She', 'believes', 'that', 'her', 'career', 'would', 'have', 'taken', 'her', 'in', 'a', 'different', 'direction', 'were', 'she', 'not', 'of', 'ethnic', 'origin', ',', 'stating', ':', '\"', 'I', 'could', 'not', 'have', 'played', 'any', 'of', 'the', 'roles', 'I', 'have', 'played', 'on', 'TV', 'if', 'I', 'was', 'white', '[', '...', ']', 'I', 'am', 'very', 'aware', 'of', 'where', 'the', 'glass', 'ceiling', 'is', 'and', 'it', \"'s\", 'still', 'very', 'low', 'and', 'expectations', 'are', 'still', 'very', 'low', '\"', '.', 'She', 'has', 'noted', 'having', 'casting', 'directors', 'accept', 'the', 'notion', 'of', 'characters', 'being', 'both', 'black', 'and', 'Welsh', 'to', 'be', 'a', 'particular', 'problem', ',', 'explaining', 'that', ':', '\"', 'I', 'get', 'offered', 'a', 'lot', 'of', 'very', 'different', 'roles', ',', 'but', 'they', \"'re\", 'never', 'Welsh', '.', '[', '...', ']', 'The', 'one', 'time', 'I', 'was', 'asked', 'to', 'play', 'a', 'Welsh', 'character', 'on', 'screen', 'was', 'in', 'Tiger', 'Bay', 'for', 'BBC', 'Wales', ',', 'but', 'I', 'know', 'if', 'that', 'series', 'had', 'been', 'called', 'Rad@@', 'yr', 'Park', 'or', 'Cyn@@', 'co@@', 'ed', 'Close', 'I', 'wouldn', \"'t\", 'have', 'been', 'in', 'it', '\"', '.', 'In', '2001', ',', 'Ay@@', 'ola', 'founded', 'a', 'production', 'company', 'and', 'directed', 'a', 'short', 'film', 'entitled', 'Per@@', 's@@', 'ephone', \"'s\", 'Play@@', 'ground', '.', 'She', 'presented', 'the', 'film', 'at', 'the', 'Cannes', 'film', 'festival', ',', 'using', 'it', 'as', 'part', 'of', 'her', 'campaign', 'for', 'increased', 'black', 'representation', 'in', 'theatre', ',', 'films', 'and', 'television', '.', 'The', 'project', ',', 'however', ',', 'was', 'largely', 'unsuccessful', ',', 'with', 'Ay@@', 'ola', 'stating', ':', '\"', 'it', 'just', 'made', 'me', 'decide', 'that', 'if', 'there', \"'s\", 'anything', 'I', 'don', \"'t\", 'want', 'to', 'do', ',', 'it', \"'s\", 'produce', 'films', ',', 'because', 'I', \"'m\", 'ru@@', 'bb@@', 'ish', 'at', 'it', '.', 'I', 'was', 'so', 'bad', 'with', 'the', 'budget', 'that', 'I', 'just', 'said', 'yes', 'to', 'everything', 'and', 'then', 'had', 'to', 'worry', 'about', 'how', 'to', 'pay', 'for', 'things', 'at', 'the', 'end', '.', '\"', 'In', '2008', ',', 'Ay@@', 'ola', 'offered', 'her', 'support', 'to', 'the', 'Action', 'for', 'Southern', 'Africa', 'campaign', 'Dig@@', 'nity', '!', 'Period', ',', 'aiming', 'to', 'provide', 'affordable', 'san@@', 'itary', 'protection', 'to', 'Zimbab@@', 'we@@', 'an', 'women', '.', '</s>', '</s>', '=', '=', '=', 'Awards', '=', '=', '=', '</s>', '</s>', 'Ay@@', 'ola', 'was', 'nominated', 'and', 'short@@', 'listed', 'for', 'the', \"'\", 'Female', 'Performance', 'in', 'TV', \"'\", 'award', 'in', 'the', '2006', 'Screen', 'Nation', 'Awards', ',', 'for', 'her', 'role', 'as', 'Ky@@', 'la', 'Tyson')\n",
      "('la', '.', 'I', \"'m\", 'very', 'sorry', 'to', 'have', 'to', 'let', 'her', 'go', '.', '\"', '</s>', '</s>', '=', '=', '=', 'Race', 'and', 'charity', 'work', '=', '=', '=', '</s>', '</s>', 'Throughout', 'her', 'career', ',', 'Ay@@', 'ola', 'has', 'been', 'outspoken', 'on', 'the', 'subject', 'of', 'racial', 'discrimination', 'in', 'the', 'entertainment', 'industry', '.', 'Describing', 'her', 'motivation', ',', 'she', 'states', ':', '\"', 'I', 'am', 'not', 'an', 'over@@', 'tly', 'political', 'person', '.', 'I', 'just', 'want', 'fair@@', 'ness', '\"', '.', 'Ay@@', 'ola', 'believes', 'that', 'black', 'actors', 'receive', 'less', 'recognition', 'than', 'their', 'white', 'counterparts', ',', 'explaining', ';', '\"', 'If', 'you', 'get', 'a', 'show', 'with', 'six', 'stars', 'and', 'one', 'is', 'black', 'you', 'are', 'more', 'likely', 'to', 'see', 'interviews', 'with', 'the', 'five', 'white', 'actors', '.', '[', '...', ']', 'They', 'are', 'not', 'being', 'sold', 'as', 'a', 'reason', 'to', 'watch', '.', '\"', 'She', 'believes', 'that', 'her', 'career', 'would', 'have', 'taken', 'her', 'in', 'a', 'different', 'direction', 'were', 'she', 'not', 'of', 'ethnic', 'origin', ',', 'stating', ':', '\"', 'I', 'could', 'not', 'have', 'played', 'any', 'of', 'the', 'roles', 'I', 'have', 'played', 'on', 'TV', 'if', 'I', 'was', 'white', '[', '...', ']', 'I', 'am', 'very', 'aware', 'of', 'where', 'the', 'glass', 'ceiling', 'is', 'and', 'it', \"'s\", 'still', 'very', 'low', 'and', 'expectations', 'are', 'still', 'very', 'low', '\"', '.', 'She', 'has', 'noted', 'having', 'casting', 'directors', 'accept', 'the', 'notion', 'of', 'characters', 'being', 'both', 'black', 'and', 'Welsh', 'to', 'be', 'a', 'particular', 'problem', ',', 'explaining', 'that', ':', '\"', 'I', 'get', 'offered', 'a', 'lot', 'of', 'very', 'different', 'roles', ',', 'but', 'they', \"'re\", 'never', 'Welsh', '.', '[', '...', ']', 'The', 'one', 'time', 'I', 'was', 'asked', 'to', 'play', 'a', 'Welsh', 'character', 'on', 'screen', 'was', 'in', 'Tiger', 'Bay', 'for', 'BBC', 'Wales', ',', 'but', 'I', 'know', 'if', 'that', 'series', 'had', 'been', 'called', 'Rad@@', 'yr', 'Park', 'or', 'Cyn@@', 'co@@', 'ed', 'Close', 'I', 'wouldn', \"'t\", 'have', 'been', 'in', 'it', '\"', '.', 'In', '2001', ',', 'Ay@@', 'ola', 'founded', 'a', 'production', 'company', 'and', 'directed', 'a', 'short', 'film', 'entitled', 'Per@@', 's@@', 'ephone', \"'s\", 'Play@@', 'ground', '.', 'She', 'presented', 'the', 'film', 'at', 'the', 'Cannes', 'film', 'festival', ',', 'using', 'it', 'as', 'part', 'of', 'her', 'campaign', 'for', 'increased', 'black', 'representation', 'in', 'theatre', ',', 'films', 'and', 'television', '.', 'The', 'project', ',', 'however', ',', 'was', 'largely', 'unsuccessful', ',', 'with', 'Ay@@', 'ola', 'stating', ':', '\"', 'it', 'just', 'made', 'me', 'decide', 'that', 'if', 'there', \"'s\", 'anything', 'I', 'don', \"'t\", 'want', 'to', 'do', ',', 'it', \"'s\", 'produce', 'films', ',', 'because', 'I', \"'m\", 'ru@@', 'bb@@', 'ish', 'at', 'it', '.', 'I', 'was', 'so', 'bad', 'with', 'the', 'budget', 'that', 'I', 'just', 'said', 'yes', 'to', 'everything', 'and', 'then', 'had', 'to', 'worry', 'about', 'how', 'to', 'pay', 'for', 'things', 'at', 'the', 'end', '.', '\"', 'In', '2008', ',', 'Ay@@', 'ola', 'offered', 'her', 'support', 'to', 'the', 'Action', 'for', 'Southern', 'Africa', 'campaign', 'Dig@@', 'nity', '!', 'Period', ',', 'aiming', 'to', 'provide', 'affordable', 'san@@', 'itary', 'protection', 'to', 'Zimbab@@', 'we@@', 'an', 'women', '.', '</s>', '</s>', '=', '=', '=', 'Awards', '=', '=', '=', '</s>', '</s>', 'Ay@@', 'ola', 'was', 'nominated', 'and', 'short@@', 'listed', 'for', 'the', \"'\", 'Female', 'Performance', 'in', 'TV', \"'\", 'award', 'in', 'the', '2006', 'Screen', 'Nation', 'Awards', ',', 'for', 'her', 'role', 'as', 'Ky@@', 'la', 'Tyson', 'in')\n",
      "487 791 305 305 Ky@@ Ky@@\n",
      "3.8316498316498318\n"
     ]
    }
   ],
   "source": [
    "# dist_list = []\n",
    "# max_dist = 0\n",
    "# index = -1\n",
    "# pd_matrix = pd_out[0][1]\n",
    "# for i, j in enumerate(pd_out[0][-1]):\n",
    "#     if pd_matrix[j, i] < 1e-2:\n",
    "#         continue\n",
    "#     dist_list.append(i-j+1)\n",
    "#     if dist_list[-1] > max_dist:\n",
    "#         max_dist = dist_list[-1]\n",
    "#         index = i\n",
    "\n",
    "# # pd_matrix = pd_out[0][1]\n",
    "# # print(pd_matrix[:100, 98])\n",
    "# print(pd_out[0][2][305:795])\n",
    "# print(pd_out[0][3][305:795])\n",
    "# print(max_dist, index, pd_out[0][-1][index], pd_out[0][-1][index], pd_out[0][2][pd_out[0][-1][index]], pd_out[0][3][index])\n",
    "# print(sum(dist_list) / len(dist_list))\n",
    "# # print(sorted(dist_list)[50])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c701b025f8f7d9f4d070fa2fa9d696adfbcb68e1d0341929514c8e0e79dfa74"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
